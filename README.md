# Matrix-Factorization-for-DNNs
In this project,we demonstrate using Matrix Factorization to reduce the number of parameters in the final layer in Deep Neural Networks (DNNs) by a percentage around 40%
without significant loss of accuracy. We demonstrate the approach in two image classification tasks with 10 and 100 target
classes with MNIST and CIFAR100 dataset and the implementation is done using Keras.

## Getting Started

You need to clone the reporistory to your local machine. Run this command in your terminal where you like to clone the project

```
git clone https://github.com/melbrbry/Matrix-Factorization-for-DNNs
```

### Prerequisites

Required packages (use pip install on linux):  
numpy  
keras

## Repository Description
The repository has only one branch: the master branch.

## Documentation
In this section, I write a brief description of some of the repository files/folders

**cifar100.py**: builds the network and train the model for cifar100 dataset.

**mnist.py**: builds the network and train the model for cifar100 dataset.

**Report.pdf**: full project report.

## Acknowledgement
- This project is done as the final project for the Neural Netowrk course taught by prof. Aurelio Uncini - Sapienza Universit√† di Roma.
- This project is an individual project.


